{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "%matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty cell intentionally, ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "DroneData = pd.read_csv('./DroneData/SP Cup 2020/IMU_camera Drone Synchronized training dataset_normal behabiour_no abnormalities/_slash_mavros_slash_imu_slash_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_normalization_params(DroneData, params = ['x','y','z','x.1','y.1','z.1','x.2','y.2','z.2']):\n",
    "    \"\"\"\n",
    "    Extracts only the normal distribution z scores \n",
    "    of from the data\n",
    "    input = Data, parameters\n",
    "    \"\"\"\n",
    "    imuParamsData = DroneData.loc[:, params]\n",
    "    normImuData = (imuParamsData - imuParamsData.mean())/imuParamsData.std()\n",
    "    return normImuData, imuParamsData.mean(), imuParamsData.std()\n",
    "\n",
    "def normalize_test_data(Data, mean, std, params = ['x','y','z','x.1','y.1','z.1','x.2','y.2','z.2']):\n",
    "    imuParamsData = Data.loc[:, params]\n",
    "    normImuData = (imuParamsData - mean)/std\n",
    "    return normImuData\n",
    "\n",
    "def find_theta_score(Data,dims=1):\n",
    "    \"\"\"\n",
    "    Converts n dimensions to a lower dimensional score,\n",
    "    for easier visualization\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=dims)\n",
    "    pca.fit(Data)\n",
    "    theta_score = pca.transform(Data)\n",
    "    return theta_score\n",
    "\n",
    "def plot_anomalies_in_1D(z_score, anomalyPrediction):\n",
    "    \"\"\"\n",
    "    plots anomalies (red) and 1D z score of the dataset\n",
    "    \"\"\"\n",
    "    for i in range(len(z_score)):\n",
    "        if anomalyPrediction[i] == True:\n",
    "            plt.scatter(i,z_score[i],c = 'r')\n",
    "    plt.plot(z_score)\n",
    "\n",
    "def plot_anomalies_in_2D(z2_score, anomalyPrediction):\n",
    "    \"\"\"\n",
    "    plots z1 and z2 as a scatter plot on x and y axes respectively,\n",
    "    with anomalies as red points and normal instances as blue\n",
    "    \"\"\"\n",
    "    for i in range(len(z2_score.T)):\n",
    "        if anomalyPrediction[i]:\n",
    "            plt.scatter(z2_score[0][i],z2_score[1][i],c = 'r')\n",
    "        else:\n",
    "            plt.scatter(z2_score[0][i],z2_score[1][i],c = 'b')\n",
    "            \n",
    "def generate_metrics(anomalyPrediction,testDataLabel):\n",
    "    \"\"\"\n",
    "    generates accuracy and detection rate metrics, takes\n",
    "    into input the prediction and the label column of the data\n",
    "    lengths of the two vectors must match\n",
    "    \"\"\"\n",
    "    actual_value = testDataLabel == 4\n",
    "    #how many readings match\n",
    "    N_set = anomalyPrediction == actual_value\n",
    "    \n",
    "    accuracy = sum(N_set)/len(testDataLabel)\n",
    "    detection_rate = sum(anomalyPrediction)/sum(actual_value)\n",
    "    false_positives = sum(np.logical_and((np.invert(actual_value)), anomalyPrediction))/len(testDataLabel)\n",
    "    false_negatives = sum(np.logical_and(actual_value, np.invert(anomalyPrediction)))/len(testDataLabel)\n",
    "    print('accuracy = ', accuracy,',detection rate =', detection_rate,'\\nfalse positive rate = '\n",
    "          ,false_positives,',false negative rate =',false_negatives)\n",
    "\n",
    "def extract_image(image):\n",
    "    \"\"\"\n",
    "    extracts image data from the unprocessed raw image dataframe\n",
    "    \"\"\"\n",
    "    preimg = image.split(', ')\n",
    "    preimg[0] = preimg[0].replace('[','')\n",
    "    preimg[-1] = preimg[-1].replace(']','')\n",
    "    img  = [int(i) for i in preimg]\n",
    "    return np.array(img).reshape(1536,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit mean and std for normalization\n",
    "\n",
    "normImuData, mean , std = extract_normalization_params(DroneData)\n",
    "trainData = normImuData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import new test data here\n",
    "testData1 = normalize_test_data(pd.concat([pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-32-12/_slash_mavros_slash_imu_slash_data.csv'),\n",
    "                                         pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-32-49/_slash_mavros_slash_imu_slash_data.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-33-26/_slash_mavros_slash_imu_slash_data.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-34-08/_slash_mavros_slash_imu_slash_data.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-34-43/_slash_mavros_slash_imu_slash_data.csv')]), mean, std)\n",
    "\n",
    "testData2 = normalize_test_data(pd.read_csv('DroneData/SP Cup 2020/04_Dataset with 5 abnormal experiments_17Jan2020/2020-01-17-11-37-25/_slash_mavros_slash_imu_slash_data.csv'), mean, std)\n",
    "z_score1 = find_theta_score(testData1)\n",
    "z_score2 = find_theta_score(testData2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:223: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/pratik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:417: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n",
      "/home/pratik/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:417: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# using IsoFo\n",
    "\n",
    "#add your algos in this very format pls\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "#fit isofo model\n",
    "clf = IsolationForest(n_estimators=1000,contamination=0.0000) #contamination parameter specifies the level of contamination in training data\n",
    "clf.fit(trainData)\n",
    "\n",
    "#predict anomalies\n",
    "tempanomalyPrediction1 = clf.predict(testData1)\n",
    "anomalyPrediction1 = tempanomalyPrediction1 == -1\n",
    "\n",
    "#isofo is statistical, so we need to specify contamination beforehand, \n",
    "#which may not be a good method since our problem is very sparse in nature\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.subplot(3,1,1)\n",
    "plot_anomalies_in_1D(z_score1, anomalyPrediction1)\n",
    "\n",
    "tempanomalyPrediction2 = clf.predict(testData2)\n",
    "anomalyPrediction2 = tempanomalyPrediction2 == -1\n",
    "plt.subplot(3,1,2)\n",
    "plot_anomalies_in_1D(z_score2, anomalyPrediction2)\n",
    "\n",
    "z2_score = find_theta_score(pd.concat([testData1, testData2],ignore_index = True),2)\n",
    "plt.subplot(3,1,3)\n",
    "plot_anomalies_in_2D(z2_score.T, np.concatenate([anomalyPrediction1, anomalyPrediction2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left blank intentionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using one class SVM\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "#fit model\n",
    "oneclass = OneClassSVM(kernel='linear', nu=0.971)\n",
    "oneclass.fit(trainData)\n",
    "\n",
    "#predict anomalies\n",
    "tempanomalyPredictionSVM1 = oneclass.predict(testData1)\n",
    "anomalyPredictionSVM1 = tempanomalyPredictionSVM1 == 1\n",
    "\n",
    "#isofo is statistical, so we need to specify contamination beforehand, \n",
    "#which may not be a good method since our problem is very sparse in nature\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.subplot(3,1,1)\n",
    "plot_anomalies_in_1D(z_score1, anomalyPredictionSVM1)\n",
    "\n",
    "tempanomalyPredictionSVM2 = oneclass.predict(testData2)\n",
    "anomalyPredictionSVM2 = tempanomalyPredictionSVM2 == 1\n",
    "plt.subplot(3,1,2)\n",
    "plot_anomalies_in_1D(z_score2, anomalyPredictionSVM2)\n",
    "plt.subplot(3,1,3)\n",
    "plot_anomalies_in_2D(z2_score.T, np.concatenate([anomalyPrediction1, anomalyPrediction2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KNN\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "params = ['x','y','z','x.1','y.1','z.1','x.2','y.2','z.2']\n",
    "#fit model\n",
    "lof = KNN()\n",
    "\n",
    "z = find_theta_score(trainData ,2)\n",
    "\n",
    "lof.fit(z)\n",
    "scores = lof.decision_scores_\n",
    "test_scores1 = lof.decision_function(find_theta_score(testData1,2))\n",
    "test_scores2 = lof.decision_function(find_theta_score(testData2,2))\n",
    "\n",
    "thres = scores.mean()+13.929*scores.std()\n",
    "anomalyPredictionLOF = test_scores1 > thres\n",
    "anomalyPredictionLOF1 = test_scores2 > thres\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.subplot(3,1,1)\n",
    "plot_anomalies_in_1D(z_score1, anomalyPredictionLOF)\n",
    "plt.subplot(3,1,2)\n",
    "plot_anomalies_in_1D(z_score2, anomalyPredictionLOF1)\n",
    "plt.subplot(3,1,3)\n",
    "plot_anomalies_in_2D(z2_score.T, np.concatenate([anomalyPredictionLOF,anomalyPredictionLOF1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for images\n",
    "\"\"\"image = pd.concat([pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-32-12/_slash_pylon_camera_node_slash_image_raw.csv'),\n",
    "                                         pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-32-49/_slash_pylon_camera_node_slash_image_raw.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-33-26/_slash_pylon_camera_node_slash_image_raw.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-34-08/_slash_pylon_camera_node_slash_image_raw.csv'),\n",
    "                                          pd.read_csv('DroneData/SP Cup 2020/03_Dataset with 5 normal experiments_17Jan2020/2020-01-17-11-34-43/_slash_pylon_camera_node_slash_image_raw.csv')],ignore_index=True)\n",
    "\"\"\"\n",
    "image = pd.read_csv('./DroneData/SP Cup 2020/04_Dataset with 5 abnormal experiments_17Jan2020/2020-01-17-11-37-25/_slash_pylon_camera_node_slash_image_raw.csv')\n",
    "#image = pd.read_csv('DroneData/SP Cup 2020/02_Initial data set for abnormalities training_2 Dec 2019/IMU_camera_Initial data set for abnormalities training_2 Dec 2019/_slash_pylon_camera_node_slash_image_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE DATA TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#animate images\n",
    "import cv2\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "im = plt.imshow(cv2.cvtColor(np.uint8(extract_image(image['data'][0])), cv2.COLOR_BayerBG2RGB), origin='lower')\n",
    "\n",
    "frame = 0\n",
    "\n",
    "def update(*args):    \n",
    "    global frame\n",
    "    rgbImage = cv2.cvtColor(np.uint8(extract_image(image['data'][frame])), cv2.COLOR_BayerBG2RGB)\n",
    "    im.set_array(rgbImage)\n",
    "\n",
    "    frame += 1\n",
    "\n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, interval=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5f1c58e4e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import skimage.measure\n",
    "def preprocess_image(image1, image2,kernal_func, kernal_size = (15,15)):\n",
    "    \"\"\"\n",
    "    find difference of current and preceeding frame, pool according to \n",
    "    kernal function and the kernel size, return the processed image\n",
    "    \"\"\"\n",
    "    a = cv2.cvtColor(np.uint8(extract_image(image1)),cv2.COLOR_BayerBG2GRAY)\n",
    "    b = cv2.cvtColor(np.uint8(extract_image(image2)),cv2.COLOR_BayerBG2GRAY)\n",
    "    dif = cv2.absdiff(skimage.measure.block_reduce(a, kernal_size, kernal_func),skimage.measure.block_reduce(b, kernal_size, kernal_func))          \n",
    "    return dif\n",
    "\n",
    "ik = preprocess_image(image['data'][0],image['data'][10], np.max)\n",
    "plt.figure(figsize = [20,8])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(cv2.cvtColor(np.uint8(extract_image(image['data'][0])),cv2.COLOR_BayerBG2RGB),origin='lower')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(cv2.cvtColor(np.uint8(extract_image(image['data'][10])),cv2.COLOR_BayerBG2RGB),origin='lower')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(ik, origin='lower', cmap = plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "im = plt.imshow(preprocess_image(image['data'][0],image['data'][1], np.max), origin='lower',cmap = plt.cm.gray)\n",
    "#im = plt.imshow(cv2.cvtColor(np.uint8(extract_image(image['data'][0])), cv2.COLOR_BayerBG2RGB), origin='lower')\n",
    "\n",
    "frame = 0\n",
    "\n",
    "def updateim(*args):    \n",
    "    global frame\n",
    "    \n",
    "    rgbImage = preprocess_image(image['data'][frame],image['data'][frame+1], np.max)\n",
    "    #rgbImage = cv2.cvtColor(np.uint8(extract_image(image['data'][frame])), cv2.COLOR_BayerBG2RGB)\n",
    "    im.set_array(rgbImage)\n",
    "    frame += 1\n",
    "    return im,\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updateim, interval=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f27c4494550>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(preprocess_image(image['data'][2],image['data'][3],np.max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
